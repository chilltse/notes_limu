{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T04:56:04.696726Z",
     "start_time": "2025-04-18T04:56:04.691367Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# dropout置零的那些元素权重不会被更新，一般 0.5 0.1 0.9\n",
    "# 如果想要可重复性的话： 用固定的随机种子+不用cudnn（并行处理，精度丢失，导致数据相加顺序不一致结果不一致）\n",
    "\n",
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    # dropout == 1：表示所有神经元都被丢弃，返回全 0。\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(X)\n",
    "    # dropout == 0：表示没有丢弃，直接返回输入。\n",
    "    if dropout == 0:\n",
    "        return X\n",
    "    # mask = ...：生成一个和输入 X 形状一样的随机 mask，元素值在 (0,1) 之间，大于 dropout 的为 1，否则为 0。\n",
    "    mask = (torch.Tensor(X.shape).uniform_(0, 1) > dropout).float()\n",
    "    # mask * X / (1.0 - dropout)：按 mask 进行丢弃操作，并除以 (1 - dropout) 进行归一化，使得在训练和测试阶段输出期望一致。\n",
    "    return mask * X / (1.0 - dropout)\n",
    "\n",
    "X = torch.arange(16, dtype=torch.float32).reshape((2, 8))\n",
    "\n",
    "print(X)\n",
    "print(dropout_layer(X, 0.0))\n",
    "print(dropout_layer(X, 0.5))\n",
    "print(dropout_layer(X, 1.0))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  2.,  4.,  0.,  8.,  0., 12.,  0.],\n",
      "        [16.,  0.,  0., 22.,  0., 26.,  0.,  0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T04:56:04.784832Z",
     "start_time": "2025-04-18T04:56:04.776316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# 网络结构的参数\n",
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\n",
    "# dropout1, dropout2 = 0.2, 0.5\n",
    "dropout1, dropout2 = 0.0, 0.0\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training=True):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.training = is_training\n",
    "        self.lin1 = nn.Linear(num_inputs, num_hiddens1)\n",
    "        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)\n",
    "        self.lin3 = nn.Linear(num_hiddens2, num_outputs)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))\n",
    "        # dropout一般作用在全连接层的输出上，只在训练的时候用\n",
    "        if self.training:\n",
    "            H1 = dropout_layer(H1, dropout1)\n",
    "        H2 = self.relu(self.lin2(H1))\n",
    "        if self.training:\n",
    "            H2 = dropout_layer(H2, dropout2)\n",
    "        out = self.lin3(H2)\n",
    "        return out\n",
    "\n",
    "net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training=True)\n"
   ],
   "id": "1ed702ba83c4f146",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T05:11:30.379251Z",
     "start_time": "2025-04-18T05:11:30.345452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from ml_utils import *\n",
    "\n",
    "# 超参数\n",
    "num_epochs, lr, batch_size = 20, 0.5, 256\n",
    "\n",
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 加载数据\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
    "\n",
    "# 初始化模型\n",
    "net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training=True)\n",
    "\n",
    "# 优化器\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "\n"
   ],
   "id": "e67985ab49f0be70",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 模型训练\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ],
   "id": "f40bf4a1c76464bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T05:14:30.072473Z",
     "start_time": "2025-04-18T05:11:33.474396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dropout简洁实现\n",
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 256),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, num_outputs),\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "\n",
    "net.apply(init_weights)\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ],
   "id": "4d671ec8f6b68752",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_metrics = (1.9759579210281373, 0.217)\n",
      "test_acc = 0.5208\n",
      "train_metrics = (0.9412045572598775, 0.6281333333333333)\n",
      "test_acc = 0.7499\n",
      "train_metrics = (0.6764810991923015, 0.7425)\n",
      "test_acc = 0.7802\n",
      "train_metrics = (0.5937331496874492, 0.7823)\n",
      "test_acc = 0.8157\n",
      "train_metrics = (0.5436917445341746, 0.80345)\n",
      "test_acc = 0.8254\n",
      "train_metrics = (0.5128901916186015, 0.8185)\n",
      "test_acc = 0.7864\n",
      "train_metrics = (0.49498618133862815, 0.8228833333333333)\n",
      "test_acc = 0.8387\n",
      "train_metrics = (0.47302289231618244, 0.8306166666666667)\n",
      "test_acc = 0.8437\n",
      "train_metrics = (0.4554902512868245, 0.8383833333333334)\n",
      "test_acc = 0.8382\n",
      "train_metrics = (0.44825654169718426, 0.8411333333333333)\n",
      "test_acc = 0.8478\n",
      "train_metrics = (0.43650185165405275, 0.8459333333333333)\n",
      "test_acc = 0.8495\n",
      "train_metrics = (0.43124554282824196, 0.84645)\n",
      "test_acc = 0.8464\n",
      "train_metrics = (0.42215665702819827, 0.8512166666666666)\n",
      "test_acc = 0.8575\n",
      "train_metrics = (0.41457356435457865, 0.8526333333333334)\n",
      "test_acc = 0.8572\n",
      "train_metrics = (0.4087824669679006, 0.8546333333333334)\n",
      "test_acc = 0.8489\n",
      "train_metrics = (0.4040664103666941, 0.85615)\n",
      "test_acc = 0.8494\n",
      "train_metrics = (0.39516079298655193, 0.8600666666666666)\n",
      "test_acc = 0.8568\n",
      "train_metrics = (0.39285012895266214, 0.8612333333333333)\n",
      "test_acc = 0.8617\n",
      "train_metrics = (0.3907698699951172, 0.85905)\n",
      "test_acc = 0.8585\n",
      "train_metrics = (0.38594913527170815, 0.8613)\n",
      "test_acc = 0.8616\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
